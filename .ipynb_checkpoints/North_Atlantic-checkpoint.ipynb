{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f108d9fc-add6-4a6f-886d-7260978e11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cart\n",
    "import cmocean\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch_geometric\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from Networks import *\n",
    "from Data_Functions import *\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from Utils import *\n",
    "from Subgrid_Funcs import *\n",
    "from Eval_Funcs import *\n",
    "from Parallel import *\n",
    "import numpy.fft as fft\n",
    "import sys\n",
    "import matplotlib.ticker as ticker\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf304a7-3e02-41c2-a956-3cf2442beb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: u_v_T_\n",
      "extra inputs: tau_u_tau_v_t_ref_\n",
      "outputs: u_v_T_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/as15415/Emulation_ICLR/Data_Functions.py:949: UserWarning: rename 'lat' to 'yt_ocean' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n",
      "  data_atmos = data_atmos.rename({\"lat\":\"yt_ocean\",\"lon\":\"xt_ocean\"})\n",
      "/scratch/as15415/Emulation_ICLR/Data_Functions.py:949: UserWarning: rename 'lon' to 'xt_ocean' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n",
      "  data_atmos = data_atmos.rename({\"lat\":\"yt_ocean\",\"lon\":\"xt_ocean\"})\n"
     ]
    }
   ],
   "source": [
    "exp_num_in = \"10\"\n",
    "exp_num_extra = \"12\"\n",
    "exp_num_out = \"6\"\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss()\n",
    "args = {}\n",
    "\n",
    "region = \"global_21\"  \n",
    "network = \"U_net_Global\"\n",
    "\n",
    "interval = 1\n",
    "\n",
    "N_samples = 4000\n",
    "N_val = 50\n",
    "N_test = 1500\n",
    "\n",
    "factor = 10\n",
    "\n",
    "hist = 0\n",
    "\n",
    "lag = 1\n",
    "\n",
    "lam = 100\n",
    "\n",
    "steps = 3\n",
    "Nb = 4\n",
    "\n",
    "\n",
    "lateral = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) > 4:\n",
    "    n_cond = int((len(sys.argv)-4)/2)\n",
    "\n",
    "str_video = \"\"\n",
    "\n",
    "\n",
    "    \n",
    "args[\"Nb\"] = Nb    \n",
    "args[\"region\"] = region\n",
    "args[\"network\"] = network\n",
    "args[\"interval\"] = interval\n",
    "args[\"N_samples\"] = N_samples\n",
    "args[\"N_val\"] = N_val\n",
    "args[\"N_test\"] = N_test\n",
    "args[\"factor\"] = factor\n",
    "args[\"hist\"] = hist\n",
    "args[\"lag\"] = lag\n",
    "args[\"steps\"] = steps\n",
    "args[\"str_video\"] = str_video\n",
    "    \n",
    "    \n",
    "s_train = lag*hist\n",
    "e_train = s_train + N_samples*interval\n",
    "e_test = e_train + interval*N_val\n",
    "\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "inpt_dict = {\"1\":[\"um\",\"vm\"],\"2\":[\"um\",\"vm\",\"ur\",\"vr\"],\"3\":[\"um\",\"vm\",\"Tm\"],\n",
    "            \"4\":[\"um\",\"vm\",\"ur\",\"vr\",\"Tm\",\"Tr\"],\"5\":[\"ur\",\"vr\"],\"6\":[\"ur\",\"vr\",\"Tr\"],\n",
    "            \"7\":[\"Tm\"],\"8\":[\"Tm\",\"Tr\"],\"9\":[\"u\",\"v\"],\"10\":[\"u\",\"v\",\"T\"],\n",
    "            \"11\":[\"tau_u\",\"tau_v\"],\"12\":[\"tau_u\",\"tau_v\",\"t_ref\"]} \n",
    "extra_dict = {\"1\":[\"ur\",\"vr\"],\"2\":[\"ur\",\"vr\",\"Tm\"],\n",
    "            \"3\":[\"Tm\"],\"4\":[\"ur\",\"vr\",\"Tm\",\"Tr\"],\"5\":[],\"6\":[\"um\",\"vm\"],\n",
    "             \"7\":[\"um\",\"vm\",\"Tm\"], \"8\": [\"um\",\"vm\",\"Tm\",\"Tr\"],\n",
    "              \"9\":[\"ur\",\"vr\",\"tau_u\",\"tau_v\"],\"10\":[\"tau_u\",\"tau_v\"],\n",
    "              \"11\":[\"ur\",\"vr\",\"Tr\"],\"12\":[\"tau_u\",\"tau_v\",\"t_ref\"],\n",
    "             \"13\":[\"ur\",\"vr\",\"Tr\",\"tau_u\",\"tau_v\",\"t_ref\"]} \n",
    "out_dict = {\"1\":[\"um\",\"vm\"],\"2\":[\"um\",\"vm\",\"Tm\"],\"3\":[\"ur\",\"vr\"],\n",
    "           \"4\":[\"ur\",\"vr\",\"Tr\"],\"5\":[\"u\",\"v\"],\"6\":[\"u\",\"v\",\"T\"]}\n",
    "\n",
    "grids = xr.open_dataset('/scratch/as15415/Data/CM2x_grids/Grid_New.nc')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "area = torch.from_numpy(grids[\"area_C\"].to_numpy()).to(device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs_str = inpt_dict[exp_num_in]\n",
    "extra_in_str = extra_dict[exp_num_extra]\n",
    "outputs_str = out_dict[exp_num_out]\n",
    "\n",
    "str_in = \"\".join([i + \"_\" for i in inputs_str])\n",
    "str_ext = \"\".join([i + \"_\" for i in extra_in_str])\n",
    "str_out = \"\".join([i + \"_\" for i in outputs_str])\n",
    "\n",
    "print(\"inputs: \" + str_in)\n",
    "print(\"extra inputs: \" + str_ext)\n",
    "print(\"outputs: \" + str_out)\n",
    "\n",
    "if lateral:\n",
    "    \n",
    "    N_atm = len(extra_in_str)\n",
    "    N_in = len(inputs_str)\n",
    "    N_extra = N_atm + N_in\n",
    "    N_out = len(outputs_str)\n",
    "else:\n",
    "    N_atm = len(extra_in_str)\n",
    "    N_in = len(inputs_str)\n",
    "    N_extra = N_atm \n",
    "    N_out = len(outputs_str)\n",
    "\n",
    "num_in = int((hist+1)*N_in + N_extra)\n",
    "\n",
    "\n",
    "inputs, extra_in, outputs = gen_data_global_new(inputs_str,extra_in_str,outputs_str,lag,run_type =\"\" )\n",
    "\n",
    "# args[\"inputs\"] = [inputs,inputs ]\n",
    "# args[\"extra_in\"] = [extra_in,extra_in ]\n",
    "# args[\"outputs\"] = [outputs,outputs ]\n",
    "\n",
    "args[\"inputs\"] = [inputs,inputs ]\n",
    "args[\"extra_in\"] = [extra_in,extra_in ]\n",
    "args[\"outputs\"] = [outputs,outputs ]\n",
    "\n",
    "wet = xr.zeros_like(inputs[0][0])\n",
    "# inputs[0][0,12,12] = np.nan\n",
    "for data in inputs:\n",
    "    wet +=np.isnan(data[0])\n",
    "wet_nan = xr.where(wet!=0,np.nan,1).to_numpy()    \n",
    "wet = np.isnan(xr.where(wet==0,np.nan,0))\n",
    "wet = np.nan_to_num(wet.to_numpy())\n",
    "wet = torch.from_numpy(wet).type(torch.float32).to(device=\"cpu\")\n",
    "wet_bool = np.array(wet.cpu()).astype(bool)\n",
    "\n",
    "wet_lap = compute_laplacian_wet(wet_nan,Nb)\n",
    "wet_lap = xr.where(wet_lap==0,1,np.nan)\n",
    "wet_lap = np.nan_to_num(wet_lap)\n",
    "wet_lap = torch.from_numpy(wet_lap).type(torch.float32).to(device=device)\n",
    "\n",
    "dx = grids[\"dx\"].to_numpy()\n",
    "dy = grids[\"dy\"].to_numpy()\n",
    "dy = dy/dx.max()\n",
    "dx = torch.from_numpy(dx/dx.max()).type(torch.float32)\n",
    "dy = torch.from_numpy(dy).type(torch.float32)    \n",
    "    \n",
    "# args[\"norm_vals\"] = norm_vals\n",
    "\n",
    "args[\"s_train\"] = s_train\n",
    "args[\"e_train\"] = e_train\n",
    "args[\"e_test\"] = e_test\n",
    "args[\"wet\"] = wet\n",
    "args[\"wet_lap\"] = wet_lap\n",
    "args[\"area\"] = area\n",
    "args[\"N_extra\"] = N_extra\n",
    "args[\"N_in\"] = N_in\n",
    "args[\"N_out\"] = N_out\n",
    "args[\"N_atm\"] = N_atm\n",
    "args[\"num_in\"] = num_in\n",
    "args[\"str_in\"] = str_in\n",
    "args[\"str_ext\"] = str_ext \n",
    "args[\"str_out\"] = str_out\n",
    "args[\"lateral\"] = lateral\n",
    "args[\"dx\"] = dx\n",
    "args[\"dy\"] = dy\n",
    "\n",
    "time_vec = inputs[0].time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9f6e0c-8e63-4862-bf83-dfc9a8c2846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_test = gen_data_in_test(0,e_test,N_test,lag,hist,inputs,extra_in)\n",
    "\n",
    "data_out_test = gen_data_out_test(0,e_test,N_test,lag,hist,outputs)\n",
    "\n",
    "test_data = data_CNN_Dynamic(data_in_test,data_out_test,wet.to(device = \"cpu\"),device=\"cpu\") \n",
    "\n",
    "\n",
    "time_test = time_vec[e_test:(e_test+lag*N_test)]\n",
    "\n",
    "mean_out = test_data.norm_vals['m_out']  \n",
    "std_out = test_data.norm_vals['s_out']  \n",
    "mean_in = test_data.norm_vals['m_in']  \n",
    "std_in = test_data.norm_vals['s_in']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3cf69a-f64e-4afe-b8d9-0565ef24366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_pred_5 = xr.open_zarr(\"/scratch/sd5313/M2Lines/emulator/Ocean_Emulator/Preds/Swin48_Train_global_1_Test_global_1_Test_in_u_v_T_ext_tau_u_tau_v_t_ref__outu_v_T_N_train_4000_Lateral_Data_025_no_smooth/Pred_lateral_Fast_Data_025_global_1_in_u_v_T_ext_tau_u_tau_v_t_ref_N_samples_4000_rand_seed_1.zarr\").to_array().to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c3a420-a2cd-49d3-8f0c-50087f491046",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nino34 = grids[\"x_C\"].loc[0:80,283:]\n",
    "x_ind = [np.argwhere(grids.xu_ocean.data==Nino34[\"xu_ocean\"][0].data),\n",
    "        np.argwhere(grids.xu_ocean.data==Nino34[\"xu_ocean\"][-1].data)]\n",
    "x_ind = [x_ind[0][0][0],x_ind[1][0][0]]\n",
    "y_ind = [np.argwhere(grids.yu_ocean.data==Nino34[\"yu_ocean\"][0].data),\n",
    "        np.argwhere(grids.yu_ocean.data==Nino34[\"yu_ocean\"][-1].data)]\n",
    "y_ind = [y_ind[0][0][0],y_ind[1][0][0]]\n",
    "area_Nino = grids[\"area_C\"].loc[0:80,283:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076e3984-a5f7-424a-bc4c-9be2da846fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = inputs[2].loc[:,0:80,283:].groupby('time.dayofyear').mean('time').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e800465-ac37-44ad-b1cd-4a07305e8990",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_pred = model_pred_5[:N_test,y_ind[0]:y_ind[1]+1,x_ind[0]:x_ind[1]+1,2]\n",
    "T_true = inputs[2][e_test:e_test+N_test,y_ind[0]:y_ind[1]+1,x_ind[0]:x_ind[1]+1].fillna(0).to_numpy()\n",
    "# T_true = T_true*std_out[2]+mean_out[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0d2f8e-aee4-49f9-bc27-20b041ce43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nino_Index(T,time_test,clim,area):\n",
    "    T = xr.DataArray(\n",
    "        data=T,\n",
    "        dims=[\"time\",\"yu_ocean\", \"xu_ocean\"],\n",
    "        coords=dict(\n",
    "            time=time_test,        \n",
    "            yu_ocean=([\"yu_ocean\"], area.yu_ocean.data),\n",
    "            xu_ocean=([\"xu_ocean\"], area.xu_ocean.data)\n",
    "\n",
    "            )\n",
    "        )\n",
    "    T_clim = copy.deepcopy(T)\n",
    "    for i in range(time_test.size):\n",
    "        day = int(time_test[i].dayofyr-1)\n",
    "        T_clim[i] = (T[i]-clim[day]).data        \n",
    "\n",
    "    T_clim = T_clim.rolling(time = 10).mean()\n",
    "    T_clim = (T_clim*area).sum([\"xu_ocean\",\"yu_ocean\"])/area.sum([\"xu_ocean\",\"yu_ocean\"])\n",
    "\n",
    "    return T_clim.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72ab9f-fd08-4afe-a421-f26bde4e6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nino_pred = Nino_Index(T_pred,time_test,clim,area_Nino)\n",
    "Nino_true = Nino_Index(T_true,time_test,clim,area_Nino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a95bd-d917-44f1-8c31-99da5cbd066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Nino_pred[150:],\"r\")\n",
    "plt.plot(Nino_true[150:],\"k\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "torch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
