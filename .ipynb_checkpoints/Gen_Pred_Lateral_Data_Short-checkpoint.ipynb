{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch_geometric\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from Networks import *\n",
    "from Data_Functions import *\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from Utils import *\n",
    "from Subgrid_Funcs import *\n",
    "import torch.distributed as dist\n",
    "\n",
    "from Parallel import *\n",
    "from Eval_Funcs import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "import sys\n",
    "import random\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cond\n",
      "inputs: um_vm_Tm_\n",
      "extra inputs: tau_u_tau_v_t_ref_\n",
      "outputs: um_vm_Tm_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/as15415/Emulation/Data_Functions.py:619: UserWarning: rename 'lat' to 'yu_ocean' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n",
      "  data_atmos = data_atmos.rename({\"lat\":\"yu_ocean\",\"lon\":\"xu_ocean\"})\n",
      "/scratch/as15415/Emulation/Data_Functions.py:619: UserWarning: rename 'lon' to 'xu_ocean' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n",
      "  data_atmos = data_atmos.rename({\"lat\":\"yu_ocean\",\"lon\":\"xu_ocean\"})\n"
     ]
    }
   ],
   "source": [
    "exp_num_in = \"3\"\n",
    "exp_num_extra = \"12\"\n",
    "exp_num_out = \"2\"\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "region = \"Gulf_Stream_Ext\"   \n",
    "network = \"U_net\"\n",
    "\n",
    "\n",
    "interval = 2\n",
    "\n",
    "N_samples = 2000\n",
    "N_val = 100\n",
    "# N_samples = 750\n",
    "# N_val = 100\n",
    "N_test = 1000\n",
    "\n",
    "factor = 10\n",
    "\n",
    "hist = 0\n",
    "\n",
    "lag = 1\n",
    "\n",
    "steps = 1\n",
    "\n",
    "Nb = 4 \n",
    "\n",
    "if len(sys.argv) > 4:\n",
    "    n_cond = int((len(sys.argv)-4)/2)\n",
    "\n",
    "str_video = \"\"\n",
    "\n",
    "try:\n",
    "    for i in range(n_cond):\n",
    "        if type(globals()[sys.argv[int(4 + i*2)]]) == str:\n",
    "            temp = str(sys.argv[int(5 + i*2)])\n",
    "            exec(sys.argv[int(4 + i*2)] +\"= temp\" )\n",
    "            if sys.argv[int(4 + i*2)] == \"network\":\n",
    "                continue\n",
    "            str_video += \"_\" + sys.argv[int(4 + i*2)] + \"_\" + sys.argv[int(5 + i*2)]\n",
    "        elif type(globals()[sys.argv[int(4 + i*2)]]) == int:\n",
    "            exec(sys.argv[int(4 + i*2)] +\"=\" + \"int(\" + sys.argv[int(5 + i*2)] +\")\" )\n",
    "            str_video += \"_\" + sys.argv[int(4 + i*2)] + \"_\" + sys.argv[int(5 + i*2)]\n",
    "    print(str_video)\n",
    "except:\n",
    "    print(\"no cond\")\n",
    "\n",
    "    \n",
    "if region == \"Kuroshio\":\n",
    "    lat = [15,41]\n",
    "    lon = [-215, -185]\n",
    "elif region == \"Kuroshio_Ext\":\n",
    "    lat = [5,50]\n",
    "    lon = [-250, -175]      \n",
    "elif region == \"Gulf_Stream\":\n",
    "    lat = [25, 50]\n",
    "    lon = [-70,-35]\n",
    "elif region == \"Gulf_Stream_Ext\":\n",
    "    lat = [27, 50]\n",
    "    lon = [-82,-35]       \n",
    "elif region == \"Tropics\":\n",
    "    lat = [-5,25]\n",
    "    lon = [-95,-65]  \n",
    "elif region == \"Tropics_Ext\":\n",
    "    lat = [-5,25]\n",
    "    lon = [-115,-45]     \n",
    "elif region == \"South_America\":\n",
    "    lat = [-60, -30]\n",
    "    lon = [-70,-35] \n",
    "elif region == \"Africa\":\n",
    "    lat = [-50, -20]\n",
    "    lon = [5,45] \n",
    "elif region == \"Quiescent\":\n",
    "    lat = [-42.5, -17.5]\n",
    "    lon = [-155,-120] \n",
    "elif region == \"Quiescent_Ext\":\n",
    "    lat = [-55, -10]\n",
    "    lon = [-170,-110]            \n",
    "elif region == \"Pacific\":\n",
    "    lat = [-35, 35]\n",
    "    lon = [-230,-80]     \n",
    "elif region == \"Indian\":\n",
    "    lat = [-30, 28]\n",
    "    lon = [30,79]     \n",
    "elif region == \"Africa_Ext\":\n",
    "    lat = [-55, -15]\n",
    "    lon = [-5,55]        \n",
    "    \n",
    "s_train = lag*hist\n",
    "e_train = s_train + N_samples*interval\n",
    "e_test = e_train + interval*N_val\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "inpt_dict = {\"1\":[\"um\",\"vm\"],\"2\":[\"um\",\"vm\",\"ur\",\"vr\"],\"3\":[\"um\",\"vm\",\"Tm\"],\n",
    "            \"4\":[\"um\",\"vm\",\"ur\",\"vr\",\"Tm\",\"Tr\"],\"5\":[\"ur\",\"vr\"],\"6\":[\"ur\",\"vr\",\"Tr\"],\n",
    "            \"7\":[\"Tm\"],\"8\":[\"Tm\",\"Tr\"],\"9\":[\"u\",\"v\"],\"10\":[\"u\",\"v\",\"T\"],\n",
    "            \"11\":[\"tau_u\",\"tau_v\"],\"12\":[\"tau_u\",\"tau_v\",\"t_ref\"]} \n",
    "extra_dict = {\"1\":[\"ur\",\"vr\"],\"2\":[\"ur\",\"vr\",\"Tm\"],\n",
    "            \"3\":[\"Tm\"],\"4\":[\"ur\",\"vr\",\"Tm\",\"Tr\"],\"5\":[],\"6\":[\"um\",\"vm\"],\n",
    "             \"7\":[\"um\",\"vm\",\"Tm\"], \"8\": [\"um\",\"vm\",\"Tm\",\"Tr\"],\n",
    "              \"9\":[\"ur\",\"vr\",\"tau_u\",\"tau_v\"],\"10\":[\"tau_u\",\"tau_v\"],\n",
    "              \"11\":[\"t_ref\"],\"12\":[\"tau_u\",\"tau_v\",\"t_ref\"],\n",
    "             \"13\":[\"ur\",\"vr\",\"Tr\",\"tau_u\",\"tau_v\",\"t_ref\"]} \n",
    "out_dict = {\"1\":[\"um\",\"vm\"],\"2\":[\"um\",\"vm\",\"Tm\"],\"3\":[\"ur\",\"vr\"],\n",
    "           \"4\":[\"ur\",\"vr\",\"Tr\"],\"5\":[\"u\",\"v\"],\"6\":[\"u\",\"v\",\"T\"]}\n",
    "\n",
    "grids = xr.open_dataset('/scratch/zanna/data/CM2_grids/Grid_cm25_Vertices.nc')\n",
    "\n",
    "if region == \"global_25\":\n",
    "    grids = xr.open_dataset('/scratch/zanna/data/CM2_grids/Grid_cm25_Vertices.nc')\n",
    "\n",
    "elif \"global\" in region:\n",
    "    grids = coarse_grid(grids,factor)\n",
    "\n",
    "else:\n",
    "    grids = grids.sel({\"yu_ocean\":slice(lat[0],lat[1]),\"xu_ocean\":slice(lon[0],lon[1])})\n",
    "\n",
    "\n",
    "area = torch.from_numpy(grids[\"area_C\"].to_numpy()).to(device=device)\n",
    "\n",
    "inputs = inpt_dict[exp_num_in]\n",
    "extra_in = extra_dict[exp_num_extra]\n",
    "outputs = out_dict[exp_num_out]\n",
    "\n",
    "str_in = \"\".join([i + \"_\" for i in inputs])\n",
    "str_ext = \"\".join([i + \"_\" for i in extra_in])\n",
    "str_out = \"\".join([i + \"_\" for i in outputs])\n",
    "\n",
    "print(\"inputs: \" + str_in)\n",
    "print(\"extra inputs: \" + str_ext)\n",
    "print(\"outputs: \" + str_out)\n",
    "\n",
    "N_atm = len(extra_in)\n",
    "N_in = len(inputs)\n",
    "N_extra = N_atm + N_in\n",
    "N_out = len(outputs)\n",
    "\n",
    "num_in = int((hist+1)*N_in + N_extra)\n",
    "\n",
    "\n",
    "inputs, extra_in, outputs = gen_data_025_lateral(inputs,extra_in,outputs,lag,lat,lon,Nb)\n",
    "\n",
    "wet = xr.zeros_like(inputs[0][0])\n",
    "# inputs[0][0,12,12] = np.nan\n",
    "for data in inputs:\n",
    "    wet +=np.isnan(data[0])\n",
    "wet = np.isnan(xr.where(wet==0,np.nan,0))\n",
    "wet = np.nan_to_num(wet.to_numpy())\n",
    "wet = torch.from_numpy(wet).type(torch.float32).to(device=\"cpu\")\n",
    "wet_bool = np.array(wet.cpu()).astype(bool)\n",
    "\n",
    "time_vec = inputs[0].time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_test = gen_data_in_test(0,e_test,N_test,lag,hist,inputs,extra_in)\n",
    "\n",
    "data_out_test = gen_data_out_test(0,e_test,N_test,lag,hist,outputs)\n",
    "\n",
    "test_data = data_CNN_Lateral(data_in_test,data_out_test,wet.to(device = \"cpu\"),N_atm,Nb,device=device) \n",
    "\n",
    "# time_test = time_vec[e_test:(e_test+lag*N_test)]\n",
    "\n",
    "mean_out = test_data.norm_vals['m_out']  \n",
    "std_out = test_data.norm_vals['s_out']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1\n",
      "data_gen\n",
      "4000 1\n",
      "data_gen\n",
      "4000 1\n",
      "data_gen\n",
      "4000 1\n",
      "data_gen\n",
      "4000 1\n",
      "data_gen\n",
      "4000 2\n",
      "data_gen\n",
      "4000 2\n",
      "data_gen\n",
      "4000 2\n",
      "data_gen\n",
      "4000 2\n",
      "data_gen\n",
      "4000 2\n",
      "data_gen\n",
      "4000 3\n",
      "data_gen\n",
      "4000 3\n",
      "data_gen\n",
      "4000 3\n",
      "data_gen\n",
      "4000 3\n",
      "data_gen\n",
      "4000 3\n",
      "data_gen\n"
     ]
    }
   ],
   "source": [
    "N_run = 5\n",
    "len_run = 200\n",
    "for ns in [4000]:\n",
    "    for rand_ind in range(1,4):\n",
    "        data_shape = test_data[0][1].shape\n",
    "        model_pred = np.zeros((int(N_run*len_run),data_shape[1],data_shape[2],data_shape[0]))        \n",
    "\n",
    "        for i in range(N_run):\n",
    "            print(ns,rand_ind)\n",
    "            if network == \"CNN\":\n",
    "                model = CNN(num_in = num_in, num_out = N_out, num_channels = 64,num_layers = 5,kernel_size=3)\n",
    "            elif network == \"U_net\":\n",
    "                model = U_net([num_in,64,128,256,512],N_out,wet.to(device=device))\n",
    "            elif network == \"U_net_RK\":\n",
    "                model = U_net_RK([num_in,64,128,256,512],N_out,wet)\n",
    "            model.to(device=device);\n",
    "#             model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/\"+network+\"_Parallel_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"N_train_1000_region_\"+region+\"_N_samples_1000_lam_0.pt\",map_location=torch.device(device)))\n",
    "#             model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/U_net_Parallel_Fast_masked_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"_out\"+str_in+\"N_train_\"+str(2000)+\"_region_\"+region+\"_rand_seed_\"+str(rand_ind)+\"_lam_\"+str(ns)+\"_Lateral_Data_025.pt\",map_location=torch.device(device)))\n",
    "#             model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/U_net_Parallel_Fast_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"_out\"+str_in+\"N_train_\"+str(2000)+\"_region_\"+region+\"_rand_seed_\"+str(rand_ind)+\"_lam_\"+str(ns)+\"_Lateral_Data_025.pt\",map_location=torch.device(device)))\n",
    "#             model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/U_net_Parallel_Fast_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"_out\"+str_in+\"N_train_\"+str(2000)+\"_region_\"+region+\"_rand_seed_\"+str(rand_ind)+\"_steps_\"+str(ns)+\"_Lateral_Data_025.pt\",map_location=torch.device(device)))\n",
    "#             model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/U_net_Parallel_Fast_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"_out\"+str_in+\"N_train_\"+str(2000)+\"_region_\"+region+\"_rand_seed_\"+str(rand_ind)+\"_steps_\"+str(ns)+\"_Lateral_Data_025.pt\",map_location=torch.device(device)))\n",
    "            model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/U_net_Parallel_Fast_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"_out\"+str_in+\"N_train_\"+str(ns)+\"_region_\"+region+\"_rand_seed_\"+str(rand_ind)+\"_N_samples_\"+str(ns)+\"_Lateral_Data_025_no_smooth.pt\",map_location=torch.device(device)))\n",
    "\n",
    "#         model.load_state_dict(torch.load(\"/scratch/as15415/Emulation/Networks/U_net_Parallel_\"+region+\"_Test_in_\"+str_in+\"ext_\"+str_ext+\"_out\"+str_out+\"N_train_750_region_\"+region+\"_rand_seed_\"+str(rand_ind)+\"_steps_\"+str(step)+\".pt\",map_location=torch.device(device)))\n",
    "            temp = copy.deepcopy(test_data)   \n",
    "            temp.input = temp.input[int(i*len_run):int((i+1)*len_run)]\n",
    "            temp.output = temp.output[int(i*len_run):int((i+1)*len_run)]\n",
    "            temp.size = len_run\n",
    "\n",
    "            model_pred_temp = recur_pred_lateral(len_run,temp,model,hist,N_in,N_extra,Nb)\n",
    "            print(\"data_gen\")\n",
    "            model_pred[int(i*len_run):int((i+1)*len_run)] = model_pred_temp\n",
    "\n",
    "        da = xr.DataArray(\n",
    "            data=model_pred,\n",
    "            dims=[\"time\",\"x\", \"y\",\"var\"],\n",
    "        )\n",
    "\n",
    "        da.to_zarr(\"/scratch/as15415/Emulation/Preds/Pred_Short_Data_025_\"+region+\"_in_\"+str_in+\"ext_\"+str_ext+\"N_samples_\"+str(ns)+\"_rand_seed_\"+str(rand_ind)+\".zarr\",mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "torch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
