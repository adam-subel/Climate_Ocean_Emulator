{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cart\n",
    "import cmocean\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch_geometric\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from Networks import *\n",
    "from Data_Functions import *\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from Utils import *\n",
    "from Subgrid_Funcs import *\n",
    "from Eval_Funcs import *\n",
    "from Parallel import *\n",
    "import numpy.fft as fft\n",
    "import sys\n",
    "import copy_things as copy\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.ticker as ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cond\n",
      "inputs: um_vm_Tm_\n",
      "extra inputs: \n",
      "outputs: um_vm_Tm_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/as15415/Emulation_ICLR/Data_Functions.py:535: UserWarning: rename 'lat' to 'yu_ocean' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n",
      "  data_atmos = data_atmos.rename({\"lat\":\"yu_ocean\",\"lon\":\"xu_ocean\"})\n",
      "/scratch/as15415/Emulation_ICLR/Data_Functions.py:535: UserWarning: rename 'lon' to 'xu_ocean' does not create an index anymore. Try using swap_dims instead or use set_index after rename to create an indexed coordinate.\n",
      "  data_atmos = data_atmos.rename({\"lat\":\"yu_ocean\",\"lon\":\"xu_ocean\"})\n"
     ]
    }
   ],
   "source": [
    "exp_num_in = \"3\"\n",
    "exp_num_extra = \"5\"\n",
    "exp_num_out = \"2\"\n",
    "\n",
    "\n",
    "mse = torch.nn.MSELoss()\n",
    "\n",
    "region = \"Gulf_Stream_Ext\"   \n",
    "network = \"U_net\"\n",
    "\n",
    "interval = 2\n",
    "\n",
    "N_samples = 2000\n",
    "N_val = 100\n",
    "N_test = 1500\n",
    "\n",
    "Nb = 4\n",
    "\n",
    "factor = 10\n",
    "\n",
    "hist = 0\n",
    "\n",
    "lag = 1\n",
    "\n",
    "steps = 1\n",
    "\n",
    "if len(sys.argv) > 4:\n",
    "    n_cond = int((len(sys.argv)-4)/2)\n",
    "\n",
    "str_video = \"\"\n",
    "\n",
    "try:\n",
    "    for i in range(n_cond):\n",
    "        if type(globals()[sys.argv[int(4 + i*2)]]) == str:\n",
    "            temp = str(sys.argv[int(5 + i*2)])\n",
    "            exec(sys.argv[int(4 + i*2)] +\"= temp\" )\n",
    "            if sys.argv[int(4 + i*2)] == \"network\":\n",
    "                continue\n",
    "            str_video += \"_\" + sys.argv[int(4 + i*2)] + \"_\" + sys.argv[int(5 + i*2)]\n",
    "        elif type(globals()[sys.argv[int(4 + i*2)]]) == int:\n",
    "            exec(sys.argv[int(4 + i*2)] +\"=\" + \"int(\" + sys.argv[int(5 + i*2)] +\")\" )\n",
    "            str_video += \"_\" + sys.argv[int(4 + i*2)] + \"_\" + sys.argv[int(5 + i*2)]\n",
    "    print(str_video)\n",
    "except:\n",
    "    print(\"no cond\")\n",
    "\n",
    "    \n",
    "if region == \"Kuroshio\":\n",
    "    lat = [15,41]\n",
    "    lon = [-215, -185]\n",
    "elif region == \"Kuroshio_Ext\":\n",
    "    lat = [5,50]\n",
    "    lon = [-250, -175]      \n",
    "elif region == \"Gulf_Stream\":\n",
    "    lat = [25, 50]\n",
    "    lon = [-70,-35]\n",
    "elif region == \"Gulf_Stream_Ext\":\n",
    "    lat = [27, 50]\n",
    "    lon = [-82,-35]       \n",
    "elif region == \"Tropics\":\n",
    "    lat = [-5,25]\n",
    "    lon = [-95,-65]  \n",
    "elif region == \"Tropics_Ext\":\n",
    "    lat = [-5,25]\n",
    "    lon = [-115,-45]     \n",
    "elif region == \"South_America\":\n",
    "    lat = [-60, -30]\n",
    "    lon = [-70,-35] \n",
    "elif region == \"Africa\":\n",
    "    lat = [-50, -20]\n",
    "    lon = [5,45] \n",
    "elif region == \"Quiescent\":\n",
    "    lat = [-42.5, -17.5]\n",
    "    lon = [-155,-120] \n",
    "elif region == \"Quiescent_Ext\":\n",
    "    lat = [-55, -10]\n",
    "    lon = [-170,-110]            \n",
    "elif region == \"Pacific\":\n",
    "    lat = [-35, 35]\n",
    "    lon = [-230,-80]     \n",
    "elif region == \"Indian\":\n",
    "    lat = [-30, 28]\n",
    "    lon = [30,79]   \n",
    "elif region == \"Africa_Ext\":\n",
    "    lat = [-55, -15]\n",
    "    lon = [-5,55]        \n",
    "        \n",
    "s_train = lag*hist\n",
    "e_train = s_train + N_samples*interval\n",
    "e_test = e_train + interval*N_val\n",
    "\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "inpt_dict = {\"1\":[\"um\",\"vm\"],\"2\":[\"um\",\"vm\",\"ur\",\"vr\"],\"3\":[\"um\",\"vm\",\"Tm\"],\n",
    "            \"4\":[\"um\",\"vm\",\"ur\",\"vr\",\"Tm\",\"Tr\"],\"5\":[\"ur\",\"vr\"],\"6\":[\"ur\",\"vr\",\"Tr\"],\n",
    "            \"7\":[\"Tm\"],\"8\":[\"Tm\",\"Tr\"],\"9\":[\"u\",\"v\"],\"10\":[\"u\",\"v\",\"T\"],\n",
    "            \"11\":[\"tau_u\",\"tau_v\"]} \n",
    "extra_dict = {\"1\":[\"ur\",\"vr\"],\"2\":[\"ur\",\"vr\",\"Tm\"],\n",
    "            \"3\":[\"Tm\"],\"4\":[\"ur\",\"vr\",\"Tm\",\"Tr\"],\"5\":[],\"6\":[\"um\",\"vm\"],\n",
    "             \"7\":[\"um\",\"vm\",\"Tm\"], \"8\": [\"um\",\"vm\",\"Tm\",\"Tr\"],\n",
    "              \"9\":[\"ur\",\"vr\",\"tau_u\",\"tau_v\"],\"10\":[\"tau_u\",\"tau_v\"],\n",
    "              \"11\":[\"ur\",\"vr\",\"Tr\"],\"12\":[\"tau_u\",\"tau_v\",\"t_ref\"]} \n",
    "out_dict = {\"1\":[\"um\",\"vm\"],\"2\":[\"um\",\"vm\",\"Tm\"],\"3\":[\"ur\",\"vr\"],\n",
    "           \"4\":[\"ur\",\"vr\",\"Tr\"],\"5\":[\"u\",\"v\"],\"6\":[\"u\",\"v\",\"T\"]}\n",
    "\n",
    "\n",
    "grids = xr.open_dataset('/scratch/zanna/data/CM2_grids/Grid_cm25_Vertices.nc')\n",
    "if \"global\" in region:\n",
    "    grids = coarse_grid(grids,factor)\n",
    "\n",
    "else:\n",
    "    grids = grids.sel({\"yu_ocean\":slice(lat[0],lat[1]),\"xu_ocean\":slice(lon[0],lon[1])})\n",
    "\n",
    "\n",
    "area = torch.from_numpy(grids[\"area_C\"].to_numpy()).to(device=device)\n",
    "dx = grids[\"dxu\"].to_numpy()\n",
    "dy = grids[\"dyu\"].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "inputs = inpt_dict[exp_num_in]\n",
    "extra_in = extra_dict[exp_num_extra]\n",
    "outputs = out_dict[exp_num_out]\n",
    "\n",
    "norm_vals = get_norms(region,inputs,extra_in,outputs)\n",
    "\n",
    "\n",
    "str_in = \"\".join([i + \"_\" for i in inputs])\n",
    "str_ext = \"\".join([i + \"_\" for i in extra_in])\n",
    "str_out = \"\".join([i + \"_\" for i in outputs])\n",
    "\n",
    "print(\"inputs: \" + str_in)\n",
    "print(\"extra inputs: \" + str_ext)\n",
    "print(\"outputs: \" + str_out)\n",
    "\n",
    "N_atm = len(extra_in)\n",
    "N_in = len(inputs)\n",
    "N_extra = N_atm + N_in\n",
    "N_out = len(outputs)\n",
    "\n",
    "num_in = int((hist+1)*N_in + N_extra)\n",
    "\n",
    "if \"global\" in region:\n",
    "    inputs, extra_in, outputs = gen_data_global(inputs,extra_in,outputs,lag)\n",
    "else:\n",
    "    inputs, extra_in, outputs = inputs, extra_in, outputs = gen_data_025_lateral(inputs,extra_in,outputs,lag,lat,lon,Nb)\n",
    "\n",
    "\n",
    "wet = xr.zeros_like(inputs[0][0])\n",
    "# inputs[0][0,12,12] = np.nan\n",
    "for data in inputs:\n",
    "    wet +=np.isnan(data[0])\n",
    "wet_nan = xr.where(wet!=0,np.nan,1).to_numpy()\n",
    "wet = xr.where(wet==0,np.nan,0)    \n",
    "wet_xr = wet.copy()\n",
    "wet = np.isnan(wet)\n",
    "wet = np.nan_to_num(wet.to_numpy())\n",
    "wet = torch.from_numpy(wet).type(torch.float32).to(device=device)\n",
    "wet_bool = np.array(wet.cpu()).astype(bool)\n",
    "\n",
    "wet_lap = compute_laplacian_wet(wet_nan,Nb)\n",
    "wet_lap = xr.where(wet_lap==0,1,np.nan)\n",
    "wet_lap = np.nan_to_num(wet_lap)\n",
    "wet_lap_bool = np.array(wet_lap).astype(bool)\n",
    "# wet_lap = torch.from_numpy(wet_lap).type(torch.float32).to(device=device)\n",
    "\n",
    "\n",
    "time_vec = inputs[0].time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = np.zeros((366,*wet.shape,3))\n",
    "for i in range(N_out):\n",
    "    clim[:,:,:,i] = outputs[i].groupby('time.dayofyear').mean('time').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_CNN_Lateral.__init__() got an unexpected keyword argument 'norms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m data_in_test \u001b[38;5;241m=\u001b[39m gen_data_in_test(\u001b[38;5;241m0\u001b[39m,e_test,N_test,lag,hist,inputs,extra_in)\n\u001b[1;32m      3\u001b[0m data_out_test \u001b[38;5;241m=\u001b[39m gen_data_out_test(\u001b[38;5;241m0\u001b[39m,e_test,N_test,lag,hist,outputs)\n\u001b[0;32m----> 5\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_CNN_Lateral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_in_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_out_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN_atm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnorms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_vals\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m time_test \u001b[38;5;241m=\u001b[39m time_vec[e_test:(e_test\u001b[38;5;241m+\u001b[39mlag\u001b[38;5;241m*\u001b[39mN_test)]\n\u001b[1;32m      9\u001b[0m mean_out \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mnorm_vals[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm_out\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n",
      "\u001b[0;31mTypeError\u001b[0m: data_CNN_Lateral.__init__() got an unexpected keyword argument 'norms'"
     ]
    }
   ],
   "source": [
    "data_in_test = gen_data_in_test(0,e_test,N_test,lag,hist,inputs,extra_in)\n",
    "\n",
    "data_out_test = gen_data_out_test(0,e_test,N_test,lag,hist,outputs)\n",
    "\n",
    "test_data = data_CNN_Lateral(data_in_test,data_out_test,wet.to(device = \"cpu\"),N_atm,Nb,device=\"cpu\",norms=norm_vals) \n",
    "\n",
    "time_test = time_vec[e_test:(e_test+lag*N_test)]\n",
    "\n",
    "mean_out = test_data.norm_vals['m_out']  \n",
    "std_out = test_data.norm_vals['s_out']  \n",
    "mean_in = test_data.norm_vals['m_in']  \n",
    "std_in = test_data.norm_vals['s_in']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "clist_1 = [cmocean.cm.thermal(i/(N-.5)) for i in range(1,N)]\n",
    "clist_2 = ['#d7191c','#abd9e9','#2c7bb6','#fdae61']\n",
    "clist_3 = [\"#91B59A\",\"#D6A922\",\"#1E88E5\",\"#A00B41\"]\n",
    "clist_5 = [\"#A00B41\",\"#00DCDE\",\"#A6BD00\",\"#3300EA\"]\n",
    "clist_6 = [\"#A00B41\",\"#DE7400\",\"#00BD8E\",\"#3300EA\"]\n",
    "clist = clist_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Time-Scale Metrics (0-200 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_1_short = xr.open_zarr(\"/scratch/as15415/Emulation/Preds/Pred_Short_Data_025_\"+region+\"_in_\"+str_in+\"ext_\"+\"tau_u_tau_v_t_ref_\"+\"N_samples_\"+str(4000)+\"_rand_seed_\"+str(1)+\".zarr\").to_array().to_numpy().squeeze()\n",
    "model_pred_2_short = xr.open_zarr(\"/scratch/as15415/Emulation/Preds/Pred_Short_Data_025_\"+region+\"_in_\"+str_in+\"ext_\"+\"tau_u_tau_v_t_ref_\"+\"lag_\"+str(2)+\"_rand_seed_\"+str(1)+\".zarr\").to_array().to_numpy().squeeze()\n",
    "model_pred_5_short = xr.open_zarr(\"/scratch/as15415/Emulation/Preds/Pred_Short_Data_025_\"+region+\"_in_\"+str_in+\"ext_\"+\"tau_u_tau_v_t_ref_\"+\"lag_\"+str(5)+\"_rand_seed_\"+str(1)+\".zarr\").to_array().to_numpy().squeeze()\n",
    "model_pred_8_short = xr.open_zarr(\"/scratch/as15415/Emulation/Preds/Pred_Short_Data_025_\"+region+\"_in_\"+str_in+\"ext_\"+\"tau_u_tau_v_t_ref_\"+\"steps_\"+str(8)+\"_rand_seed_\"+str(1)+\".zarr\").to_array().to_numpy().squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic Energy\n",
    "$\\frac{1}{2} \\rho (u^2 +v^2)$\n",
    "\n",
    "We look at kinetic energy in the domain for two reasons: \n",
    "1) The first is to simply ensure that we match the correct amount of energy in the system. If our models routinely produce fields with too low kinetic energy we are likely missing features, perhaps too few eddies or just features with smaller magnitudes. If the kinetic energy is too large, we are likely getting too many unphysical features, or the model is producing a lot of activity in regions that do not typically have much dynamics going on. \n",
    "2) The second reason is to get a sense of what scales are present in the domain. We use the isotropic fourier transform (we average across each radius of the 2D fourier transform) of kinetic energy to plot energy as a function of spatial frequency. There is a lot of very physical dynamics that cause the spectrum to look the way it does, but the general idea is that we have some dominant low frequency modes and then a gradual drop in energy as we move to the small scales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_plot = 200\n",
    "\n",
    "KE_spec_1, KE_spec_true = gen_KE_spectrum(N_plot,test_data,model_pred_1_short,grids,wet)\n",
    "KE_spec_2, KE_spec_true = gen_KE_spectrum(int(N_plot/2),test_data,model_pred_2_short,grids,wet)\n",
    "KE_spec_5, KE_spec_true = gen_KE_spectrum(int(N_plot/5),test_data,model_pred_5_short,grids,wet)\n",
    "KE_spec_8, KE_spec_true = gen_KE_spectrum(N_plot,test_data,model_pred_8_short,grids,wet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(KE_spec_1.freq_r,KE_spec_1,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.loglog(KE_spec_2.freq_r,KE_spec_2,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.loglog(KE_spec_5.freq_r,KE_spec_5,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.loglog(KE_spec_8.freq_r,KE_spec_8,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.loglog(KE_spec_true.freq_r,KE_spec_true,\"--k\")\n",
    "\n",
    "plt.legend(loc= \"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_plot = 200\n",
    "\n",
    "KE_1, KE_true = compute_KE(N_plot,test_data,model_pred_1_short,area,wet_bool)\n",
    "KE_2, KE_true = compute_KE(int(N_plot/2),test_data,model_pred_2_short,area,wet_bool)\n",
    "KE_5, KE_true = compute_KE(int(N_plot/5),test_data,model_pred_5_short,area,wet_bool)\n",
    "KE_8, KE_true = compute_KE(N_plot,test_data,model_pred_8_short,area,wet_bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 1020\n",
    "\n",
    "plt.plot(np.arange(1,N_plot+1),KE_1*rho,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.plot(np.arange(2,N_plot+1,2),KE_2*rho,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.plot(np.arange(5,N_plot+1,5),KE_5*rho,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.plot(np.arange(1,N_plot+1),KE_8*rho,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.plot(np.arange(1,N_plot+1),KE_true*rho,\"--k\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"Kinetic Energy\")\n",
    "plt.legend(loc= \"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enstrophy\n",
    "$\\omega^2 = (\\nabla_{h}\\times \\mathbf{u}_h)^2$\n",
    "\n",
    "Enstrophy is another important physical quantity 2D, or quasi-2D turbelence and similar to energy gives a sense of spatial scales in the system. Unlike kinetic energy, which is based directly on the velocity fields, enstrophy is computed as the square of the vorticity (2D curl in this case) and give some information on how our models reproduce derivatives of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_plot = 200\n",
    "\n",
    "enst_spec_1, enst_spec_true = gen_enstrophy_spectrum(N_plot,test_data,model_pred_1_short,grids,wet,wet_lap)\n",
    "enst_spec_2, enst_spec_true = gen_enstrophy_spectrum(int(N_plot/2),test_data,model_pred_2_short,grids,wet,wet_lap)\n",
    "enst_spec_5, enst_spec_true = gen_enstrophy_spectrum(int(N_plot/5),test_data,model_pred_5_short,grids,wet,wet_lap)\n",
    "enst_spec_8, enst_spec_true = gen_enstrophy_spectrum(N_plot,test_data,model_pred_8_short,grids,wet,wet_lap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(enst_spec_1.freq_r,enst_spec_1,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.loglog(enst_spec_2.freq_r,enst_spec_2,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.loglog(enst_spec_5.freq_r,enst_spec_5,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.loglog(enst_spec_8.freq_r,enst_spec_8,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.loglog(enst_spec_true.freq_r,enst_spec_true,\"--k\")\n",
    "\n",
    "plt.legend(loc= \"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_plot = 200\n",
    "\n",
    "enst_1, enst_true = gen_enstrophy(N_plot,test_data,model_pred_1_short,dx, dy, Nb, wet_lap)\n",
    "enst_1 = enst_1.mean(axis=(1,2))\n",
    "enst_2, enst_true = gen_enstrophy(int(N_plot/2),test_data,model_pred_2_short,dx, dy, Nb, wet_lap)\n",
    "enst_2 = enst_2.mean(axis=(1,2))\n",
    "enst_5, enst_true = gen_enstrophy(int(N_plot/5),test_data,model_pred_5_short,dx, dy, Nb, wet_lap)\n",
    "enst_5 = enst_5.mean(axis=(1,2))\n",
    "enst_8, enst_true = gen_enstrophy(N_plot,test_data,model_pred_8_short,dx, dy, Nb, wet_lap)\n",
    "enst_8 = enst_8.mean(axis=(1,2))\n",
    "enst_true = enst_true.mean(axis=(1,2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(1,N_plot+1),enst_1,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.plot(np.arange(2,N_plot+1,2),enst_2,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.plot(np.arange(5,N_plot+1,5),enst_5,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.plot(np.arange(1,N_plot+1),enst_8,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.plot(np.arange(1,N_plot+1),enst_true,\"--k\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(\"Enstrophy\")\n",
    "plt.legend(loc= \"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Matching Statistics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = np.array(test_data[:][1][:,0]*std_out[0] +mean_out[0])\n",
    "v_test = np.array(test_data[:][1][:,1]*std_out[1] +mean_out[1])\n",
    "T_test = np.array(test_data[:][1][:,2]*std_out[2] +mean_out[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficient\n",
    "\n",
    "The general correlation coefficient gives how well the predicted spatial field correlated with the ground truth. In slowly evolving fields such as temperature, this is dominated by seasonal changes and so this metric can remain high, even if the model is failing to capture faster, but smaller scale dynamics. \n",
    "\n",
    "$CC(u,\\tilde{u}) = \\frac{\\sum_{i,j}^{N_x,N_y}A_{i,j}W_{i,j}u_{i,j}\\tilde{u}_{i,j}}{\\sqrt{\\sum_{i,j}^{N_x,N_y}\\left( A_{i,j}W_{i,j}u_{i,j} \\right)^2\\sum_{i,j}^{N_x,N_y}\\left( A_{i,j}W_{i,j}\\tilde{u}_{i,j} \\right)^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_eval = 200\n",
    "corr_T_1, corr_T_true = compute_corrs_single(N_eval, T_test, model_pred_1_short[:,:,:,2],area, wet_bool,std_out[2],mean_out[2])\n",
    "corr_T_2, corr_T_true = compute_corrs_single(int(N_eval/2), T_test[::2], model_pred_2_short[:,:,:,2],area, wet_bool,std_out[2],mean_out[2])\n",
    "corr_T_5, corr_T_true = compute_corrs_single(int(N_eval/5), T_test[::5], model_pred_5_short[:,:,:,2],area, wet_bool,std_out[2],mean_out[2])\n",
    "corr_T_8, corr_T_true = compute_corrs_single(N_eval, T_test, model_pred_8_short[:,:,:,2],area, wet_bool,std_out[2],mean_out[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(1,N_eval+1),corr_T_1,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.plot(np.arange(2,N_eval+1,2),corr_T_2,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.plot(np.arange(5,N_eval+1,5),corr_T_5,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.plot(np.arange(1,N_eval+1),corr_T_8,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.plot(np.arange(1,N_eval+1),corr_T_true,\"--k\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(r\"Correlation $T$\")\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,N_eval])\n",
    "\n",
    "plt.legend(loc= \"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Correlation Coefficient\n",
    "\n",
    "The anomaly correlation coefficient gives how well the predicted spatial field correlated with the anomalies outside of seasonality. To compute this we remove the sesonal pointwise mean from the ground truth and the prediction and then compute the correlation as is standard. For example, if we compute this for a January 30th, we average over all January 30ths and remove that from both the truth and prediction before computing the CC.\n",
    "\n",
    "$ACC(u,\\tilde{u}) = \\frac{\\sum_{i,j}^{N_x,N_y}A_{i,j}W_{i,j}(u_{i,j}-C_{i,j})(\\tilde{u}_{i,j}-C_{i,j})}{\\sqrt{\\sum_{i,j}^{N_x,N_y}A_{i,j}W_{i,j}\\left( u_{i,j}-C_{i,j} \\right)^2\\sum_{i,j}^{N_x,N_y}A_{i,j}W_{i,j}\\left( \\tilde{u}_{i,j}-C_{i,j} \\right)^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_eval = 100\n",
    "ACC_T_1, ACC_T_true = compute_ACC_single(N_eval, T_test, model_pred_1_short[:,:,:,2],\n",
    "                                         clim[:,:,:,2],time_test,area, wet_bool)\n",
    "ACC_T_2, ACC_T_true = compute_ACC_single(int(N_eval/2), T_test[::2], model_pred_2_short[:,:,:,2],\n",
    "                                         clim[:,:,:,2],time_test,area, wet_bool)\n",
    "ACC_T_5, ACC_T_true = compute_ACC_single(int(N_eval/5), T_test[::5], model_pred_5_short[:,:,:,2],\n",
    "                                         clim[:,:,:,2],time_test,area, wet_bool)\n",
    "ACC_T_8, ACC_T_true = compute_ACC_single(N_eval, T_test, model_pred_8_short[:,:,:,2],\n",
    "                                         clim[:,:,:,2],time_test,area, wet_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(1,N_eval+1),ACC_T_1,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.plot(np.arange(2,N_eval+1,2),ACC_T_2,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.plot(np.arange(5,N_eval+1,5),ACC_T_5,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.plot(np.arange(1,N_eval+1),ACC_T_8,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.plot(np.arange(1,N_eval+1),ACC_T_true,\"--k\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(r\"ACC $T$\")\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,N_eval])\n",
    "\n",
    "plt.legend(loc= \"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Errror\n",
    "\n",
    "RMSE gives a sense of how far away the prediction is from the ground truth. This distance is irrespective of the similarity in spatial patterns and would grow if two correlated fields are off by a scalar value.\n",
    "\n",
    "$RMSE(u,\\tilde{u}) = \\sqrt{\\frac{\\sum_{i,j}^{N_x,N_y}A_{i,j}W_{i,j}(u_{i,j}-\\tilde{u}_{i,j})^2}{\\sum_{i,j}^{N_x,N_y}A_{i,j}W_{i,j}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_eval = 200\n",
    "RMSE_T_1, RMSE_T_true = compute_RMSE_single(N_eval, T_test, model_pred_1_short[:,:,:,2],\n",
    "                                         area, wet_bool)\n",
    "RMSE_T_2, RMSE_T_true = compute_RMSE_single(int(N_eval/2), T_test[::2], model_pred_2_short[:,:,:,2],\n",
    "                                         area, wet_bool)\n",
    "RMSE_T_5, RMSE_T_true = compute_RMSE_single(int(N_eval/5), T_test[::5], model_pred_5_short[:,:,:,2],\n",
    "                                         area, wet_bool)\n",
    "RMSE_T_8, RMSE_T_true = compute_RMSE_single(N_eval, T_test, model_pred_8_short[:,:,:,2],\n",
    "                                         area, wet_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(np.arange(1,N_eval+1),RMSE_T_1,c=clist[0],label = r\"$\\Delta t = 1$\")\n",
    "plt.plot(np.arange(2,N_eval+1,2),RMSE_T_2,c=clist[1],label = r\"$\\Delta t = 2$\")\n",
    "plt.plot(np.arange(5,N_eval+1,5),RMSE_T_5,c=clist[2],label = r\"$\\Delta t = 5$\")\n",
    "plt.plot(np.arange(1,N_eval+1),RMSE_T_8,c=clist[3],label = r\"$\\Delta t = 1,~ N = 8$\")\n",
    "\n",
    "plt.plot(np.arange(1,N_eval+1),RMSE_T_true,\"--k\")\n",
    "plt.xlabel(\"time (days)\")\n",
    "plt.ylabel(r\"RMSE $T$\")\n",
    "plt.xlim([0,N_eval])\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "torch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
